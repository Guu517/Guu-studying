# 机器学习概念入门

1. 机器学习是从数据中自动分析获得模型，并利用模型对未知数据进行预测

2. 监督学习(Supervised learning)和无监督学习(Unsupervised learning)是实际应用中使用最多的机器学习类型

## 监督学习

监督学习使用有标签的数据来训练模型，训练集有输入x和标签y，从给定正确的xy映射组合中学习到特征，并且实现在只给x的情况下得到合理的预测

例如，垃圾邮件判断、语音识别、机器翻译、线上广告推送、自动驾驶车辆图像识别、产品质量检测等

主要解决两种类型的问题：①分类；②回归

1. 分类任务可以对样本进行类别区分，输出的内容为离散值，标签对应到具体数字上
2. 回归任务可以预测一个连续的值，比如股价/房价预测，将影响预测对象的因素称为**特征**
3. 使用特征组合，用特征向量来表征待预测的对象，特征向量包含了n个特征，每个特征都是一维，因此称为n维特征向量
4. 机器学习中所有特征都要转为数值来处理

## 无监督学习

无监督学习是让机器自主发掘数据的内在结构，训练集没有标签，只有输入。

在无监督学习中，我们只提供了一堆没有标签的数据，然后让算法自己进行聚类分析、关联规则挖掘、降维等操作，来发现数据中的隐藏模式和结构。无监督学习通常用于数据探索、发现隐藏关系和提取特征等任务。

例如，我们有一堆顾客的购物历史数据，但是没有任何标签来说明他们的购买偏好，这时候我们可以使用无监督学习中的聚类算法，将顾客分成不同的群组，根据这些群组可以了解不同群组的购买偏好和行为模式。

<!--聚类算法（无监督学习算法）可能把未标注的数据分配给两个不同的组或者两个不同的集群 -->

## 半监督学习

利用少量有标签的样本和大量无标签的样本进行机器学习

半监督学习（Semi-supervised learning）是介于无监督学习和有监督学习之间的一种学习方式。在半监督学习中，我们既有一部分有标签的数据（有指导性的信息），也有一部分没有标签的数据

目标是利用有标签的数据来指导和辅助模型训练，同时充分利用无标签的数据来提高模型的泛化能力。

例如，大规模文本分类、图像分类等任务

## 强化学习

机器通过与环境的交互来实现目标的一种算法，目标是开发智能体，通过环境的反馈(称为奖励reward)来提高决策的正确性，是让机器在与环境进行交互的过程中学习最优行为策略的方法。

例如，AlphaGo将棋局的输赢作为反馈自我调整，使每一步决策都以回报最大化为目标。

## 数据集

在机器学习中，我们通常会将数据集分为训练集、验证集和测试集。这三个数据集的作用是为了帮助我们评估和优化机器学习模型的性能。

**训练集**（Training set）是用来训练模型的数据集。它是我们用来构建和调整模型的主要数据源。通过使用训练集，我们可以让模型学习数据中的模式和规律，从而得出预测模型。

**验证集**（Validation set）用于模型的选择和调整。在训练过程中，我们通常会根据验证集的性能来进行模型的调整和优化。验证集相当于是训练过程中的“实验室”，我们可以在验证集上尝试不同的参数、算法或模型架构，以找到最佳的模型。

**测试集**（Test set）用于评估模型的最终性能。在训练和验证之后，我们使用测试集来评估模型的泛化能力，也就是模型对未知数据的预测能力。通过测试集的评估，我们可以得出模型的性能指标，例如准确率、召回率等，从而对模型的效果有一个客观的判断。

## 过拟合

过拟合（Overfitting）和欠拟合（Underfitting）分别表示了模型在训练过程中出现的两种不良情况。

**过拟合**指模型在训练过程中过于追求数据的细节和噪音，导致模型在训练集上表现很好，但在未见过的数据上表现较差。简单来说，过拟合就是“记住了太多的细节”。这种情况下，模型可能学到了训练数据中的一些特殊的规律，而这些规律在真实场景中并不具备泛化能力。

例如，我们想要训练一个识别猫和狗的模型。如果将模型训练得过于复杂，在训练集上反复训练，模型可能会过度记住训练集中每个猫和狗的细节，比如花纹、颜色等。这样的模型可能会在训练集上表现出色，但在真实世界中，无法正确识别新的猫和狗。

## 欠拟合

**欠拟合**指模型无法拟合训练数据的特征和规律，导致模型在训练集和验证集上的性能表现都较差，不能很好地预测新的样本。简单来说，欠拟合就是“没有学到足够的知识”。这种情况下，模型可能过于简单，无法捕捉到数据中的复杂模式和规律。

例如，我们使用一个非常简单的模型，如使用线性模型来识别猫和狗，那么这个模型可能无法捕捉到图像中猫和狗的复杂特征，导致无法正确识别它们。

<!--为了解决过拟合和欠拟合问题，需要在模型训练的过程中找到一个合适的平衡点。可以使用如数据集的划分、正则化技术、调节模型复杂度等-->

## 损失函数

**损失函数**是机器学习中一种衡量模型预测与真实结果之间差异的方式。

如果模型的预测结果和真实结果非常接近，也就是预测准确，那么模型的损失就会很低。这说明模型在这个样本上的预测比较准确。我们的目标是通过调整模型的参数和权重，减小损失函数的值，提高模型的准确性。

例如，均方误差（Mean Squared Error）和交叉熵损失（Cross Entropy Loss）

## 模型评价指标

**模型评价指标**用来衡量模型的预测结果与真实结果之间的接近程度。常见的模型评价指标有准确率、精确率、召回率、F1值等，帮助我们评估模型好坏，并选择合适的模型来进行预测任务。

**准确率**（Accuracy）是一个常用的评价指标，表示模型预测正确的样本占总样本数的比例。例如，如果有100个样本，模型正确预测了80个样本，那么准确率就是80%。

**精确率**（Precision）和召回率（Recall）则是用来评价二分类模型的性能。精确率表示在所有预测为正类别的样本中，有多少是真正的正样本；而召回率表示在所有真实的正样本中，有多少被模型预测出来了。这两个指标一起评价模型的性能更加全面。

**F1值**是精确率和召回率的综合指标，它是精确率和召回率的调和平均值，可以综合考虑模型的预测准确性和召回率。

根据不同的任务和需求，还有比如R2评价回归模型的性能、AUC-ROC评价二分类模型的性能等。

## 数据清洗

**数据清洗**是指对数据集进行处理和修复，以确保数据的准确性、完整性和一致性。在上一期泰坦尼克数据集可视化中我使用了数据清洗，比如使用均值/中位值填充缺失数据，或删去少量有空缺的数据等方式，或根据其它相关信息推测填充缺失值和修正错误数据。

## 特征工程

**特征工程**是指对原始数据进行处理和增强，提取和构造有意义的特征，帮助机器学习模型更好理解数据和进行预测。

例如，在预测一个房屋的价格时，特征可以包括房屋的面积、卧室数量、地理位置等。而特征工程就是对这些特征进行处理和优化的过程。

1. 特征选择：选择最相关或最具有代表性的特征，去除无关或冗余的特征，以减少模型的复杂性和提高训练效果。
2. 特征变换：对原始特征进行数学操作，如对数变换、标准化、归一化等，以使特征更适合模型的要求。
3. 特征构建：基于原始特征构建新的特征，如通过加减乘除原始特征得到新的特征，或者提取时间序列数据中的周期性特征等。
4. 特征编码：将非数值特征转化为数值特征，以用于机器学习模型的训练。常见的方法包括独热编码、标签编码等。
5. 特征降维：通过某些算法或技术将原始数据的维度减少，保留最具有代表性的特征，以减少模型的复杂性和计算成本。

<!--特征选择不会改变特征的表达方式，特征降维对原始特征进行变换和组合，可能会合并特征或生成新的特征-->

